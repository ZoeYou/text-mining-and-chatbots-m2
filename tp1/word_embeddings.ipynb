{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - Text Mining and Chatbots\n",
    "\n",
    "Name: Jiangnan Huang and You Zuo\n",
    "\n",
    "Date: 14/01/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:13.821708Z",
     "start_time": "2021-01-14T17:17:13.811523Z"
    }
   },
   "outputs": [],
   "source": [
    "# libraries required\n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:20.777641Z",
     "start_time": "2021-01-14T17:17:20.747656Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[!?,.\\'\\`]\", \" \", string)   \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "# reads the content of the file passed as an argument.\n",
    "# if limit > 0, this function will return only the first \"limit\" sentences in the file.\n",
    "def loadTexts(filename, limit=-1):\n",
    "    f = open(filename, \"r\", encoding='utf-8')\n",
    "    dataset=[]\n",
    "    line =  f.readline()\n",
    "    cpt=1\n",
    "    skip=0\n",
    "    while line :\n",
    "        cleanline = clean_str(line).split()\n",
    "        if cleanline: \n",
    "            dataset.append(cleanline)\n",
    "        else: \n",
    "            line = f.readline()\n",
    "            skip+=1\n",
    "            continue\n",
    "        if limit > 0 and cpt >= limit: \n",
    "            break\n",
    "        line = f.readline()\n",
    "        cpt+=1        \n",
    "        \n",
    "    f.close()\n",
    "    print(\"Load \", cpt, \" lines from \", filename , \" / \", skip ,\" lines discarded\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:22.243361Z",
     "start_time": "2021-01-14T17:17:21.302042Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load  3022  lines from  TP_ISD2020/QUAERO_FrenchMed/QUAERO_FrenchMed_traindev.ospl  /  70  lines discarded\n",
      "Load  38547  lines from  TP_ISD2020/QUAERO_FrenchPress/QUAERO_FrenchPress_traindev.ospl  /  2  lines discarded\n"
     ]
    }
   ],
   "source": [
    "filename1 = 'TP_ISD2020/QUAERO_FrenchMed/QUAERO_FrenchMed_traindev.ospl'\n",
    "filename2 = 'TP_ISD2020/QUAERO_FrenchPress/QUAERO_FrenchPress_traindev.ospl'\n",
    "\n",
    "data1 = loadTexts(filename1)\n",
    "data2 = loadTexts(filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings training\n",
    "\n",
    "The first step of the work is to create python and bash scripts to train the different embeddings approaches: word2vec (Cbow, skipgram) and fasttext (Cbow), on the two medical and non-medical corpora, resulting to 6 embeddings models.\n",
    "\n",
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:26.863236Z",
     "start_time": "2021-01-14T17:17:24.127640Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(687560, 933100)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "## word2vec: CBow\n",
    "\n",
    "### parameters:\n",
    "### sg = 0 for cbow, 1 for skipgram\n",
    "### min_count: ignores all words with total frequency lower than this.\n",
    "### size: dimension of the word vector\n",
    "### window: maximum distance between the current and predicted word within a sentence\n",
    "\n",
    "## cbow trained on data1\n",
    "w2v_cbow1 = Word2Vec(sg=0, min_count=1, size=100, window=10)\n",
    "w2v_cbow1.build_vocab(sentences=data1)\n",
    "w2v_cbow1.train(data1,total_examples=w2v_cbow1.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T15:13:22.439722Z",
     "start_time": "2021-01-14T15:12:54.662502Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16747921, 22751300)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "## cbow trained on data2\n",
    "w2v_cbow2 = Word2Vec(sg=0, min_count=1, size=100, window=10)\n",
    "w2v_cbow2.build_vocab(sentences=data2)\n",
    "w2v_cbow2.train(data2,total_examples=w2v_cbow2.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T15:13:43.891086Z",
     "start_time": "2021-01-14T15:13:37.342128Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(687615, 933100)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# word2vec: skipgram\n",
    "## skipgram trained on data1\n",
    "w2v_sg1 = Word2Vec(sg=1, min_count=1, size=100, window=10)\n",
    "w2v_sg1.build_vocab(sentences=data1)\n",
    "w2v_sg1.train(data1,total_examples=w2v_sg1.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T15:16:29.862902Z",
     "start_time": "2021-01-14T15:14:43.684252Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16749108, 22751300)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "## skipgram trained on data2\n",
    "w2v_sg2 = Word2Vec(sg=1, min_count=1, size=100, window=10)\n",
    "w2v_sg2.build_vocab(sentences=data2)\n",
    "w2v_sg2.train(data2,total_examples=w2v_sg2.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:19:56.248657Z",
     "start_time": "2021-01-14T17:17:34.973079Z"
    }
   },
   "outputs": [],
   "source": [
    "# with the same hyper-paramters with word2vec\n",
    "fasttext1 = FastText(data1, min_count=1, size=100, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:24:33.308016Z",
     "start_time": "2021-01-14T17:20:17.581648Z"
    }
   },
   "outputs": [],
   "source": [
    "fasttext2 = FastText(data2, min_count=1, size=100, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:15:46.535770Z",
     "start_time": "2021-01-14T17:15:46.103128Z"
    }
   },
   "outputs": [],
   "source": [
    "# save six models\n",
    "\n",
    "w2v_cbow1.save(\"models/cbow_medical.model\")\n",
    "w2v_cbow2.save(\"models/cbow_non-medical.model\")\n",
    "w2v_sg1.save(\"models/skipgram_medical.model\")\n",
    "w2v_sg2.save(\"models/skipgram_non-medical.model\")\n",
    "fasttext1.save(\"models/fasttext_medical.model\")\n",
    "fasttext2.save(\"models/fasttext_non-medical.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic similarity\n",
    "\n",
    "The second step is to find the closest words to a given word based on the cosine similarity calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the same corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:01:46.932821Z",
     "start_time": "2021-01-14T17:01:46.929548Z"
    }
   },
   "outputs": [],
   "source": [
    "# the candidate word list\n",
    "test_words = ['patient', 'traitement', 'maladie', 'solution', 'jaune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:13:04.855576Z",
     "start_time": "2021-01-14T17:13:04.097108Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n",
      "('symptômes', 0.9948393106460571)\n",
      "('carte', 0.8920832872390747)\n",
      "('patiente', 0.9999991655349731) \n",
      "\n",
      "traitement:\n",
      "('expérience', 0.9797210693359375)\n",
      "('confirmé', 0.7372004985809326)\n",
      "('taaitement', 0.9999992251396179) \n",
      "\n",
      "maladie:\n",
      "('infection', 0.986403226852417)\n",
      "('liée', 0.8259382247924805)\n",
      "('maladies', 0.9999959468841553) \n",
      "\n",
      "solution:\n",
      "('conditionnés', 0.9839076399803162)\n",
      "('réchauffer', 0.910857617855072)\n",
      "('dissolution', 0.9999986886978149) \n",
      "\n",
      "jaune:\n",
      "('capsule', 0.9976205229759216)\n",
      "('blanc', 0.878764271736145)\n",
      "('une', 0.9999926090240479) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_medical = Word2Vec.load('models/cbow_medical.model')\n",
    "skipgram_medical = Word2Vec.load('models/skipgram_medical.model')\n",
    "fasttext_medical = FastText.load('models/fasttext_medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(cbow_medical.wv.most_similar(word)[0])\n",
    "    print(skipgram_medical.wv.most_similar(word)[0])\n",
    "    print(fasttext_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T16:23:51.228067Z",
     "start_time": "2021-01-14T16:23:51.215289Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n",
      "('mototaxi', 0.5873354077339172)\n",
      "('hospitalisé', 0.6993711590766907)\n",
      "('contient', 0.9885638356208801) \n",
      "\n",
      "traitement:\n",
      "('système', 0.7244834899902344)\n",
      "('médicamenteux', 0.5807715654373169)\n",
      "('farouchement', 0.9810761213302612) \n",
      "\n",
      "maladie:\n",
      "('perte', 0.5813629627227783)\n",
      "('neurologique', 0.6623693108558655)\n",
      "('trilogie', 0.9433014988899231) \n",
      "\n",
      "solution:\n",
      "('alternative', 0.6969314813613892)\n",
      "('lancinant', 0.6705160140991211)\n",
      "('résolution', 0.9928999543190002) \n",
      "\n",
      "jaune:\n",
      "('maillot', 0.883590817451477)\n",
      "('maillot', 0.8162438273429871)\n",
      "('lune', 0.9673931002616882) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_non_medical = Word2Vec.load('models/cbow_non-medical.model')\n",
    "skipgram_non_medical = Word2Vec.load('models/skipgram_non-medical.model')\n",
    "fasttext_non_medical = FastText.load('models/fasttext_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(cbow_non_medical.wv.most_similar(word)[0])\n",
    "    print(skipgram_non_medical.wv.most_similar(word)[0])\n",
    "    print(fasttext_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on different corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:15:51.227393Z",
     "start_time": "2021-01-14T17:15:50.428924Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n('symptômes', 0.9948393106460571)\n('mototaxi', 0.5873354077339172) \n\ntraitement:\n('expérience', 0.9797210693359375)\n('système', 0.7244834899902344) \n\nmaladie:\n('infection', 0.986403226852417)\n('perte', 0.5813629627227783) \n\nsolution:\n('conditionnés', 0.9839076399803162)\n('alternative', 0.6969314813613892) \n\njaune:\n('capsule', 0.9976205229759216)\n('maillot', 0.883590817451477) \n\n"
     ]
    }
   ],
   "source": [
    "cbow_medical = Word2Vec.load('models/cbow_medical.model')\n",
    "cbow_non_medical = Word2Vec.load('models/cbow_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(cbow_medical.wv.most_similar(word)[0])\n",
    "    print(cbow_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n('carte', 0.8920832872390747)\n('hospitalisé', 0.6993711590766907) \n\ntraitement:\n('confirmé', 0.7372004985809326)\n('médicamenteux', 0.5807715654373169) \n\nmaladie:\n('liée', 0.8259382247924805)\n('neurologique', 0.6623693108558655) \n\nsolution:\n('réchauffer', 0.910857617855072)\n('lancinant', 0.6705160140991211) \n\njaune:\n('blanc', 0.878764271736145)\n('maillot', 0.8162438273429871) \n\n"
     ]
    }
   ],
   "source": [
    "skipgram_medical = Word2Vec.load('models/skipgram_medical.model')\n",
    "skipgram_non_medical = Word2Vec.load('models/skipgram_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(skipgram_medical.wv.most_similar(word)[0])\n",
    "    print(skipgram_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n",
      "('patiente', 0.9999991655349731)\n",
      "('contient', 0.9885638356208801) \n",
      "\n",
      "traitement:\n",
      "('taaitement', 0.9999992251396179)\n",
      "('farouchement', 0.9810761213302612) \n",
      "\n",
      "maladie:\n",
      "('maladies', 0.9999959468841553)\n",
      "('trilogie', 0.9433014988899231) \n",
      "\n",
      "solution:\n",
      "('dissolution', 0.9999986886978149)\n",
      "('résolution', 0.9928999543190002) \n",
      "\n",
      "jaune:\n",
      "('une', 0.9999926090240479)\n",
      "('lune', 0.9673931002616882) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasttext_medical = Word2Vec.load('models/fasttext_medical.model')\n",
    "fasttext_non_medical = Word2Vec.load('models/fasttext_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(fasttext_medical.wv.most_similar(word)[0])\n",
    "    print(fasttext_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}