{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 - Text Mining and Chatbots\n",
    "\n",
    "Name: Jiangnan Huang and You Zuo\n",
    "\n",
    "Date: 14/01/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:13.821708Z",
     "start_time": "2021-01-14T17:17:13.811523Z"
    }
   },
   "outputs": [],
   "source": [
    "# libraries required\n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:20.777641Z",
     "start_time": "2021-01-14T17:17:20.747656Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for dataset\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[!?,.\\'\\`]\", \" \", string)   \n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)    \n",
    "    return string.strip().lower()\n",
    "\n",
    "\n",
    "# reads the content of the file passed as an argument.\n",
    "# if limit > 0, this function will return only the first \"limit\" sentences in the file.\n",
    "def loadTexts(filename, limit=-1):\n",
    "    f = open(filename, \"r\", encoding='utf-8')\n",
    "    dataset=[]\n",
    "    line =  f.readline()\n",
    "    cpt=1\n",
    "    skip=0\n",
    "    while line :\n",
    "        cleanline = clean_str(line).split()\n",
    "        if cleanline: \n",
    "            dataset.append(cleanline)\n",
    "        else: \n",
    "            line = f.readline()\n",
    "            skip+=1\n",
    "            continue\n",
    "        if limit > 0 and cpt >= limit: \n",
    "            break\n",
    "        line = f.readline()\n",
    "        cpt+=1        \n",
    "        \n",
    "    f.close()\n",
    "    print(\"Load \", cpt, \" lines from \", filename , \" / \", skip ,\" lines discarded\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:22.243361Z",
     "start_time": "2021-01-14T17:17:21.302042Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load  3022  lines from  ../TP_ISD2020/QUAERO_FrenchMed/QUAERO_FrenchMed_traindev.ospl  /  70  lines discarded\n",
      "Load  38547  lines from  ../TP_ISD2020/QUAERO_FrenchPress/QUAERO_FrenchPress_traindev.ospl  /  2  lines discarded\n"
     ]
    }
   ],
   "source": [
    "filename1 = '../TP_ISD2020/QUAERO_FrenchMed/QUAERO_FrenchMed_traindev.ospl'\n",
    "filename2 = '../TP_ISD2020/QUAERO_FrenchPress/QUAERO_FrenchPress_traindev.ospl'\n",
    "\n",
    "data1 = loadTexts(filename1)\n",
    "data2 = loadTexts(filename2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings training\n",
    "\n",
    "The first step of the work is to create python and bash scripts to train the different embeddings approaches: word2vec (Cbow, skipgram) and fasttext (Cbow), on the two medical and non-medical corpora, resulting to 6 embeddings models.\n",
    "\n",
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:17:26.863236Z",
     "start_time": "2021-01-14T17:17:24.127640Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(687391, 933100)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "## word2vec: CBow\n",
    "\n",
    "### parameters:\n",
    "### sg = 0 for cbow, 1 for skipgram\n",
    "### min_count: ignores all words with total frequency lower than this.\n",
    "### size: dimension of the word vector\n",
    "### window: maximum distance between the current and predicted word within a sentence\n",
    "\n",
    "## cbow trained on data1\n",
    "w2v_cbow1 = Word2Vec(sg=0, min_count=1, size=100, window=10)\n",
    "w2v_cbow1.build_vocab(sentences=data1)\n",
    "w2v_cbow1.train(data1,total_examples=w2v_cbow1.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T15:13:22.439722Z",
     "start_time": "2021-01-14T15:12:54.662502Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16750313, 22751300)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "## cbow trained on data2\n",
    "w2v_cbow2 = Word2Vec(sg=0, min_count=1, size=100, window=10)\n",
    "w2v_cbow2.build_vocab(sentences=data2)\n",
    "w2v_cbow2.train(data2,total_examples=w2v_cbow2.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T15:13:43.891086Z",
     "start_time": "2021-01-14T15:13:37.342128Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(687479, 933100)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# word2vec: skipgram\n",
    "## skipgram trained on data1\n",
    "w2v_sg1 = Word2Vec(sg=1, min_count=1, size=100, window=10)\n",
    "w2v_sg1.build_vocab(sentences=data1)\n",
    "w2v_sg1.train(data1,total_examples=w2v_sg1.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T15:16:29.862902Z",
     "start_time": "2021-01-14T15:14:43.684252Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16749052, 22751300)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "## skipgram trained on data2\n",
    "w2v_sg2 = Word2Vec(sg=1, min_count=1, size=100, window=10)\n",
    "w2v_sg2.build_vocab(sentences=data2)\n",
    "w2v_sg2.train(data2,total_examples=w2v_sg2.corpus_count, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:19:56.248657Z",
     "start_time": "2021-01-14T17:17:34.973079Z"
    }
   },
   "outputs": [],
   "source": [
    "# with the same hyper-paramters with word2vec\n",
    "fasttext1 = FastText(data1, min_count=1, size=100, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:24:33.308016Z",
     "start_time": "2021-01-14T17:20:17.581648Z"
    }
   },
   "outputs": [],
   "source": [
    "fasttext2 = FastText(data2, min_count=1, size=100, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:15:46.535770Z",
     "start_time": "2021-01-14T17:15:46.103128Z"
    }
   },
   "outputs": [],
   "source": [
    "# save six models\n",
    "\n",
    "w2v_cbow1.save(\"models/cbow_medical.model\")\n",
    "w2v_cbow2.save(\"models/cbow_non-medical.model\")\n",
    "w2v_sg1.save(\"models/skipgram_medical.model\")\n",
    "w2v_sg2.save(\"models/skipgram_non-medical.model\")\n",
    "fasttext1.save(\"models/fasttext_medical.model\")\n",
    "fasttext2.save(\"models/fasttext_non-medical.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic similarity\n",
    "\n",
    "The second step is to find the closest words to a given word based on the cosine similarity calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the same corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:01:46.932821Z",
     "start_time": "2021-01-14T17:01:46.929548Z"
    }
   },
   "outputs": [],
   "source": [
    "# the candidate word list\n",
    "test_words = ['patient', 'traitement', 'maladie', 'solution', 'jaune']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:13:04.855576Z",
     "start_time": "2021-01-14T17:13:04.097108Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n",
      "('symptômes', 0.994620680809021)\n",
      "('carte', 0.8950115442276001)\n",
      "('patiente', 0.9999990463256836) \n",
      "\n",
      "traitement:\n",
      "('expérience', 0.9798558354377747)\n",
      "('six', 0.7178391218185425)\n",
      "('taaitement', 0.9999990463256836) \n",
      "\n",
      "maladie:\n",
      "('aggravation', 0.9832441806793213)\n",
      "('recklinghausen', 0.8165718913078308)\n",
      "('malade', 0.9999963045120239) \n",
      "\n",
      "solution:\n",
      "('conditionnés', 0.9851862192153931)\n",
      "('réchauffer', 0.9186955690383911)\n",
      "('dissolution', 0.9999988079071045) \n",
      "\n",
      "jaune:\n",
      "('initial', 0.9970934391021729)\n",
      "('blanc', 0.8862963318824768)\n",
      "('une', 0.9999927878379822) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_medical = Word2Vec.load('models/cbow_medical.model')\n",
    "skipgram_medical = Word2Vec.load('models/skipgram_medical.model')\n",
    "fasttext_medical = FastText.load('models/fasttext_medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(cbow_medical.wv.most_similar(word)[0])\n",
    "    print(skipgram_medical.wv.most_similar(word)[0])\n",
    "    print(fasttext_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T16:23:51.228067Z",
     "start_time": "2021-01-14T16:23:51.215289Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n",
      "('flagrant', 0.5910066366195679)\n",
      "('soignant', 0.7369797229766846)\n",
      "('patientent', 0.9877076745033264) \n",
      "\n",
      "traitement:\n",
      "('système', 0.7374351620674133)\n",
      "('médicamenteux', 0.5933451652526855)\n",
      "('promptement', 0.9832788705825806) \n",
      "\n",
      "maladie:\n",
      "('douleur', 0.6258751153945923)\n",
      "('dingue', 0.6802621483802795)\n",
      "('malnutrie', 0.9487839937210083) \n",
      "\n",
      "solution:\n",
      "('alternative', 0.6906707286834717)\n",
      "('lancinant', 0.626539409160614)\n",
      "('révolution', 0.9928566217422485) \n",
      "\n",
      "jaune:\n",
      "('maillot', 0.8880891799926758)\n",
      "('maillot', 0.7969251871109009)\n",
      "('lune', 0.9644564986228943) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cbow_non_medical = Word2Vec.load('models/cbow_non-medical.model')\n",
    "skipgram_non_medical = Word2Vec.load('models/skipgram_non-medical.model')\n",
    "fasttext_non_medical = FastText.load('models/fasttext_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(cbow_non_medical.wv.most_similar(word)[0])\n",
    "    print(skipgram_non_medical.wv.most_similar(word)[0])\n",
    "    print(fasttext_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on different corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-14T17:15:51.227393Z",
     "start_time": "2021-01-14T17:15:50.428924Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n('symptômes', 0.994620680809021)\n('flagrant', 0.5910066366195679) \n\ntraitement:\n('expérience', 0.9798558354377747)\n('système', 0.7374351620674133) \n\nmaladie:\n('aggravation', 0.9832441806793213)\n('douleur', 0.6258751153945923) \n\nsolution:\n('conditionnés', 0.9851862192153931)\n('alternative', 0.6906707286834717) \n\njaune:\n('initial', 0.9970934391021729)\n('maillot', 0.8880891799926758) \n\n"
     ]
    }
   ],
   "source": [
    "cbow_medical = Word2Vec.load('models/cbow_medical.model')\n",
    "cbow_non_medical = Word2Vec.load('models/cbow_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(cbow_medical.wv.most_similar(word)[0])\n",
    "    print(cbow_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n('carte', 0.8950115442276001)\n('soignant', 0.7369797229766846) \n\ntraitement:\n('six', 0.7178391218185425)\n('médicamenteux', 0.5933451652526855) \n\nmaladie:\n('recklinghausen', 0.8165718913078308)\n('dingue', 0.6802621483802795) \n\nsolution:\n('réchauffer', 0.9186955690383911)\n('lancinant', 0.626539409160614) \n\njaune:\n('blanc', 0.8862963318824768)\n('maillot', 0.7969251871109009) \n\n"
     ]
    }
   ],
   "source": [
    "skipgram_medical = Word2Vec.load('models/skipgram_medical.model')\n",
    "skipgram_non_medical = Word2Vec.load('models/skipgram_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(skipgram_medical.wv.most_similar(word)[0])\n",
    "    print(skipgram_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "patient:\n",
      "('patiente', 0.9999990463256836)\n",
      "('patientent', 0.9877076745033264) \n",
      "\n",
      "traitement:\n",
      "('taaitement', 0.9999990463256836)\n",
      "('promptement', 0.9832788705825806) \n",
      "\n",
      "maladie:\n",
      "('malade', 0.9999963045120239)\n",
      "('malnutrie', 0.9487839937210083) \n",
      "\n",
      "solution:\n",
      "('dissolution', 0.9999988079071045)\n",
      "('révolution', 0.9928566217422485) \n",
      "\n",
      "jaune:\n",
      "('une', 0.9999927878379822)\n",
      "('lune', 0.9644564986228943) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "fasttext_medical = Word2Vec.load('models/fasttext_medical.model')\n",
    "fasttext_non_medical = Word2Vec.load('models/fasttext_non-medical.model')\n",
    "\n",
    "for word in test_words:\n",
    "    print(word+':')\n",
    "    print(fasttext_medical.wv.most_similar(word)[0])\n",
    "    print(fasttext_non_medical.wv.most_similar(word)[0],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "12px",
    "width": "160px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}